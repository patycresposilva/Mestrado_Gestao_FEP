{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Screening_date</th>\n",
       "      <th>nscreens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-03-03</td>\n",
       "      <td>11.169861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-03-04</td>\n",
       "      <td>11.169861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-03-05</td>\n",
       "      <td>11.169861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-03-06</td>\n",
       "      <td>11.169861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-03-07</td>\n",
       "      <td>11.169861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>775</th>\n",
       "      <td>2024-04-16</td>\n",
       "      <td>12.874846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>776</th>\n",
       "      <td>2024-04-17</td>\n",
       "      <td>12.874846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>777</th>\n",
       "      <td>2024-04-18</td>\n",
       "      <td>12.874846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>778</th>\n",
       "      <td>2024-04-19</td>\n",
       "      <td>12.874846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>779</th>\n",
       "      <td>2024-04-20</td>\n",
       "      <td>12.874846</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>780 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Screening_date   nscreens\n",
       "0       2022-03-03  11.169861\n",
       "1       2022-03-04  11.169861\n",
       "2       2022-03-05  11.169861\n",
       "3       2022-03-06  11.169861\n",
       "4       2022-03-07  11.169861\n",
       "..             ...        ...\n",
       "775     2024-04-16  12.874846\n",
       "776     2024-04-17  12.874846\n",
       "777     2024-04-18  12.874846\n",
       "778     2024-04-19  12.874846\n",
       "779     2024-04-20  12.874846\n",
       "\n",
       "[780 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel('C:/Users/Patyc/OneDrive/Desktop/Dissertation/Data/Skin_clean and treated/Skin_clean_location.xlsx')\n",
    "df['Location'] = df['Location'].str.strip()\n",
    "df.loc[df['Location'].eq('Faro') & df['Screening_date'].eq('2022-08-13'), 'Screening_date'] = '2022-08-14'\n",
    "df.loc[df['Location'].eq('Lisboa') & df['Screening_date'].eq('2023-05-15'), 'Screening_date'] = '2023-05-19'\n",
    "\n",
    "df.head()\n",
    "\n",
    "d1 = df.groupby(['Location', 'Screening_date'], as_index=False).size().sort_values(['Location', 'Screening_date'])\n",
    "d2 = d1.assign(count = d1.groupby(['Location'])['Location'].transform('count'))\n",
    "d2 = d2[d2['count'].ne(1)]\n",
    "\n",
    "d2['ndays'] = d2.groupby('Location')['Screening_date'].diff()\n",
    "d2['nscreens'] = d2['size'].values/d2['ndays'].dt.days\n",
    "d2\n",
    "\n",
    "date_range = pd.date_range(start='2022-03-03', end='2024-04-20') #datas mais extremas no dataset\n",
    "\n",
    "datesdf = pd.DataFrame(date_range, columns=['Screening_date'])\n",
    "\n",
    "list_dfs = []\n",
    "\n",
    "groups = d2.groupby('Location')\n",
    "\n",
    "for _, group in groups:\n",
    "    list_dfs.append(datesdf.merge(group, how='left').bfill().ffill())\n",
    "\n",
    "d3 = pd.concat(list_dfs)\n",
    "d3\n",
    "\n",
    "# Agrupar por 'Screening_date' e calcular a soma de 'nscreens' para cada data (ou use outra função agregada como média)\n",
    "d4 = d3.groupby('Screening_date', as_index=False)['nscreens'].sum()\n",
    "\n",
    "d4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Resultados do teste ADF:\n",
      "ADF Statistic: -1.1583735563439237\n",
      "p-value: 0.6912413038161388\n",
      "Used Lag: 0\n",
      "Number of Observations: 779\n",
      "Critical Values:\n",
      "   1%: -3.4387723094153286\n",
      "   5%: -2.8652573313919625\n",
      "   10%: -2.5687494684274794\n",
      "Não rejeitamos a hipótese nula: a série não é estacionária.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "# Supondo que 'd4' já foi criado conforme você descreveu\n",
    "\n",
    "# 1. Realizar o teste ADF para verificar a estacionaridade\n",
    "result = adfuller(d4['nscreens'])\n",
    "\n",
    "# 2. Extrair e imprimir os resultados\n",
    "adf_statistic = result[0]\n",
    "p_value = result[1]\n",
    "used_lag = result[2]\n",
    "n_observations = result[3]\n",
    "critical_values = result[4]\n",
    "\n",
    "print('\\nResultados do teste ADF:')\n",
    "print('ADF Statistic:', adf_statistic)\n",
    "print('p-value:', p_value)\n",
    "print('Used Lag:', used_lag)\n",
    "print('Number of Observations:', n_observations)\n",
    "print('Critical Values:')\n",
    "for key, value in critical_values.items():\n",
    "    print(f'   {key}: {value}')\n",
    "\n",
    "# 3. Interpretação dos resultados\n",
    "if p_value < 0.05:\n",
    "    print(\"Rejeitamos a hipótese nula: a série é estacionária.\")\n",
    "else:\n",
    "    print(\"Não rejeitamos a hipótese nula: a série não é estacionária.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Resultados do teste ADF:\n",
      "ADF Statistic: -1.1583735563439237\n",
      "p-value: 0.6912413038161388\n",
      "Valores Críticos: {'1%': -3.4387723094153286, '5%': -2.8652573313919625, '10%': -2.5687494684274794}\n",
      "A série não é estacionária.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "# Realizar o teste ADF na coluna 'nscreens' do DataFrame 'd4'\n",
    "result = adfuller(d4['nscreens'])\n",
    "\n",
    "# Extrair resultados do teste\n",
    "adf_statistic = result[0]\n",
    "p_value = result[1]\n",
    "critical_values = result[4]\n",
    "\n",
    "# Imprimir resultados\n",
    "print('\\nResultados do teste ADF:')\n",
    "print('ADF Statistic:', adf_statistic)\n",
    "print('p-value:', p_value)\n",
    "print('Valores Críticos:', critical_values)\n",
    "\n",
    "# Interpretação\n",
    "if p_value < 0.05:\n",
    "    print(\"A série é estacionária.\")\n",
    "else:\n",
    "    print(\"A série não é estacionária.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Resultados do teste ADF:\n",
      "ADF Statistic: -27.82622137870492\n",
      "p-value: 0.0\n",
      "Used Lag: 0\n",
      "Number of Observations: 776\n",
      "Critical Values:\n",
      "   1%: -3.438804978547988\n",
      "   5%: -2.8652717302548396\n",
      "   10%: -2.5687571389759802\n",
      "Rejeitamos a hipótese nula: a série é estacionária.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "# Supondo que 'd4' já foi criado e contém a coluna 'nscreens'\n",
    "\n",
    "# Aplicar diferenciação\n",
    "d4['nscreens_diff'] = d4['nscreens'].diff()\n",
    "\n",
    "# Remover NaN que podem surgir da diferenciação\n",
    "d4 = d4.dropna()\n",
    "\n",
    "# Realizar o teste ADF na nova série 'nscreens_diff'\n",
    "result = adfuller(d4['nscreens_diff'])\n",
    "\n",
    "# 2. Extrair e imprimir os resultados\n",
    "adf_statistic = result[0]\n",
    "p_value = result[1]\n",
    "used_lag = result[2]\n",
    "n_observations = result[3]\n",
    "critical_values = result[4]\n",
    "\n",
    "print('\\nResultados do teste ADF:')\n",
    "print('ADF Statistic:', adf_statistic)\n",
    "print('p-value:', p_value)\n",
    "print('Used Lag:', used_lag)\n",
    "print('Number of Observations:', n_observations)\n",
    "print('Critical Values:')\n",
    "for key, value in critical_values.items():\n",
    "    print(f'   {key}: {value}')\n",
    "\n",
    "# 3. Interpretação dos resultados\n",
    "if p_value < 0.05:\n",
    "    print(\"Rejeitamos a hipótese nula: a série é estacionária.\")\n",
    "else:\n",
    "    print(\"Não rejeitamos a hipótese nula: a série não é estacionária.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.874845651448748\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "max_value = d4['nscreens'].max()\n",
    "print(max_value)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LR MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supondo que o DataFrame 'df' já esteja carregado com as colunas 'Screening_date' e 'nscreens'\n",
    "d4['Screening_date'] = pd.to_datetime(d4['Screening_date'])\n",
    "\n",
    "# Converter 'Screening_date' para número de dias desde a data mínima\n",
    "d4['days_since_start'] = (d4['Screening_date'] - d4['Screening_date'].min()).dt.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Screening_date</th>\n",
       "      <th>nscreens</th>\n",
       "      <th>days_since_start</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-03-03</td>\n",
       "      <td>11.169861</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-03-04</td>\n",
       "      <td>11.169861</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-03-05</td>\n",
       "      <td>11.169861</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-03-06</td>\n",
       "      <td>11.169861</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-03-07</td>\n",
       "      <td>11.169861</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>775</th>\n",
       "      <td>2024-04-16</td>\n",
       "      <td>12.874846</td>\n",
       "      <td>775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>776</th>\n",
       "      <td>2024-04-17</td>\n",
       "      <td>12.874846</td>\n",
       "      <td>776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>777</th>\n",
       "      <td>2024-04-18</td>\n",
       "      <td>12.874846</td>\n",
       "      <td>777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>778</th>\n",
       "      <td>2024-04-19</td>\n",
       "      <td>12.874846</td>\n",
       "      <td>778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>779</th>\n",
       "      <td>2024-04-20</td>\n",
       "      <td>12.874846</td>\n",
       "      <td>779</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>780 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Screening_date   nscreens  days_since_start\n",
       "0       2022-03-03  11.169861                 0\n",
       "1       2022-03-04  11.169861                 1\n",
       "2       2022-03-05  11.169861                 2\n",
       "3       2022-03-06  11.169861                 3\n",
       "4       2022-03-07  11.169861                 4\n",
       "..             ...        ...               ...\n",
       "775     2024-04-16  12.874846               775\n",
       "776     2024-04-17  12.874846               776\n",
       "777     2024-04-18  12.874846               777\n",
       "778     2024-04-19  12.874846               778\n",
       "779     2024-04-20  12.874846               779\n",
       "\n",
       "[780 rows x 3 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# Definir X como 'days_since_start' e y como 'nscreens'\n",
    "X = d4['days_since_start'].values.reshape(-1, 1)\n",
    "y = d4['nscreens'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividir os dados em conjuntos de treinamento e teste (80% treinamento e 20% teste)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajustar o modelo de Regressão Linear ao conjunto de treinamento\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Gerar previsões para o conjunto de teste\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo: LR\n",
      "MAE: 3.0452899244104197\n",
      "MSE: 13.792722910901267\n",
      "RMSE: 3.7138555317757405\n",
      "R2: -2.636951405291359\n",
      "ME: 3.0452899244104197\n",
      "MAV: 11.228988121444878\n",
      "MPV: 0.2441679433808033\n",
      "RME: 0.2441679433808033\n",
      "RMAE: 0.2441679433808033\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "\n",
    "# Calcular e imprimir as métricas de avaliação\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "me = np.mean(y_test - y_pred)\n",
    "mav = np.mean(np.abs(y_test))\n",
    "mpv = np.mean(np.abs((y_test - y_pred) / y_test))\n",
    "rme = np.mean((y_test - y_pred) / y_test)\n",
    "rmae = np.mean(np.abs(y_test - y_pred) / np.abs(y_test))\n",
    "\n",
    "print(\"Modelo: LR\")\n",
    "print(f'MAE: {mae}')\n",
    "print(f'MSE: {mse}')\n",
    "print(f'RMSE: {rmse}')\n",
    "print(f'R2: {r2}')\n",
    "print(f'ME: {me}')\n",
    "print(f'MAV: {mav}')\n",
    "print(f'MPV: {mpv}')\n",
    "print(f'RME: {rme}')\n",
    "print(f'RMAE: {rmae}')\n",
    "\n",
    "# Modelo: LR shuffle\n",
    "# MAE: 3.0452899244104197\n",
    "# MSE: 13.792722910901267\n",
    "# RMSE: 3.7138555317757405\n",
    "# R2: -2.636951405291359\n",
    "# ME: 3.0452899244104197\n",
    "# MAV: 11.228988121444878\n",
    "# MPV: 0.2441679433808033\n",
    "# RME: 0.2441679433808033\n",
    "# RMAE: 0.2441679433808033"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir X como 'days_since_start' e y como 'nscreens'\n",
    "X = d4['days_since_start'].values.reshape(-1, 1)\n",
    "y = d4['nscreens'].values\n",
    "\n",
    "# Converter a coluna de data para o formato datetime, se ainda não estiver nesse formato\n",
    "d4['Screening_date'] = pd.to_datetime(d4['Screening_date'])\n",
    "\n",
    "# Definir a data de corte\n",
    "split_date = pd.to_datetime('2024-03-01')\n",
    "\n",
    "# Separar o dataset em treino e teste\n",
    "train_data = d4[d4['Screening_date'] < split_date]\n",
    "test_data = d4[d4['Screening_date'] >= split_date]\n",
    "\n",
    "# Definir X e y para o conjunto de treino\n",
    "X_train = train_data['days_since_start'].values.reshape(-1, 1)\n",
    "y_train = train_data['nscreens'].values\n",
    "\n",
    "# Definir X e y para o conjunto de teste\n",
    "X_test = test_data['days_since_start'].values.reshape(-1, 1)\n",
    "y_test = test_data['nscreens'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo: LR\n",
      "MAE: 3.7142565243426153\n",
      "MSE: 13.79678381467565\n",
      "RMSE: 3.7144022149836773\n",
      "R2: -4.372375320973177e+30\n",
      "ME: 3.7142565243426153\n",
      "MAV: 12.874845651448746\n",
      "MPV: 0.2884894021175833\n",
      "RME: 0.2884894021175833\n",
      "RMAE: 0.2884894021175833\n"
     ]
    }
   ],
   "source": [
    "# Treinar o modelo de Regressão Linear\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Fazer previsões\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calcular e imprimir as métricas de avaliação\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "me = np.mean(y_test - y_pred)\n",
    "mav = np.mean(np.abs(y_test))\n",
    "mpv = np.mean(np.abs((y_test - y_pred) / y_test))\n",
    "rme = np.mean((y_test - y_pred) / y_test)\n",
    "rmae = np.mean(np.abs(y_test - y_pred) / np.abs(y_test))\n",
    "\n",
    "print(\"Modelo: LR\")\n",
    "print(f'MAE: {mae}')\n",
    "print(f'MSE: {mse}')\n",
    "print(f'RMSE: {rmse}')\n",
    "print(f'R2: {r2}')\n",
    "print(f'ME: {me}')\n",
    "print(f'MAV: {mav}')\n",
    "print(f'MPV: {mpv}')\n",
    "print(f'RME: {rme}')\n",
    "print(f'RMAE: {rmae}')\n",
    "\n",
    "# Modelo: LR split date\n",
    "# MAE: 3.7142565243426153\n",
    "# MSE: 13.79678381467565\n",
    "# RMSE: 3.7144022149836773\n",
    "# R2: -4.372375320973177e+30\n",
    "# ME: 3.7142565243426153\n",
    "# MAV: 12.874845651448746\n",
    "# MPV: 0.2884894021175833\n",
    "# RME: 0.2884894021175833\n",
    "# RMAE: 0.2884894021175833"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential # type: ignore\n",
    "from tensorflow.keras.layers import LSTM, Dense # type: ignore\n",
    "from tensorflow.keras.optimizers import Adam # type: ignore\n",
    "\n",
    "# Normalização dos dados da coluna 'nscreens'\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled_data = scaler.fit_transform(d4['nscreens'].values.reshape(-1, 1))\n",
    "\n",
    "# Função para criar sequências de dados\n",
    "def create_sequences(data, seq_length):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - seq_length):\n",
    "        X.append(data[i:i+seq_length])\n",
    "        y.append(data[i+seq_length])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# Definir o tamanho da sequência (por exemplo, 10 dias)\n",
    "seq_length = 7\n",
    "X, y = create_sequences(scaled_data, seq_length)\n",
    "\n",
    "# Dividir em conjuntos de treino e teste\n",
    "train_size = int(len(X) * 0.8)\n",
    "X_train, X_test = X[:train_size], X[train_size:]\n",
    "y_train, y_test = y[:train_size], y[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Patyc\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 28ms/step - loss: 0.0797 - val_loss: 0.0258\n",
      "Epoch 2/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0071 - val_loss: 0.0193\n",
      "Epoch 3/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0022 - val_loss: 0.0228\n",
      "Epoch 4/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0014 - val_loss: 0.0207\n",
      "Epoch 5/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0012 - val_loss: 0.0202\n",
      "Epoch 6/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0013 - val_loss: 0.0207\n",
      "Epoch 7/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0015 - val_loss: 0.0201\n",
      "Epoch 8/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0013 - val_loss: 0.0201\n",
      "Epoch 9/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0013 - val_loss: 0.0201\n",
      "Epoch 10/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0017 - val_loss: 0.0199\n",
      "Epoch 11/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0011 - val_loss: 0.0201\n",
      "Epoch 12/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 9.8272e-04 - val_loss: 0.0197\n",
      "Epoch 13/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.2210e-04 - val_loss: 0.0197\n",
      "Epoch 14/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0014 - val_loss: 0.0196\n",
      "Epoch 15/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0011 - val_loss: 0.0198\n",
      "Epoch 16/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0010 - val_loss: 0.0196\n",
      "Epoch 17/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0015 - val_loss: 0.0193\n",
      "Epoch 18/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0014 - val_loss: 0.0193\n",
      "Epoch 19/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 9.8305e-04 - val_loss: 0.0191\n",
      "Epoch 20/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0014 - val_loss: 0.0190\n"
     ]
    }
   ],
   "source": [
    "# Construir o modelo LSTM\n",
    "model = Sequential()\n",
    "model.add(LSTM(units=50, return_sequences=True, input_shape=(X_train.shape[1], 1)))\n",
    "model.add(LSTM(units=50))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Treinamento do modelo\n",
    "history = model.fit(X_train, y_train, epochs=20, batch_size=32, validation_data=(X_test, y_test), verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "Modelo: LSTM\n",
      "MAE: 0.11717208185219818\n",
      "MSE: 0.33863664634657764\n",
      "RMSE: 0.5819249490669546\n",
      "R2: 0.9104699094832556\n",
      "ME: 0.11578682865341078\n",
      "MAV: 11.2438539313933\n",
      "MPV: 0.009124663507374167\n",
      "RME: 0.008969449370739846\n",
      "RMAE: 0.009124663507374167\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score # type: ignore\n",
    "import numpy as np # type: ignore\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Fazer previsões no conjunto de teste\n",
    "predicted = model.predict(X_test)\n",
    "predicted = scaler.inverse_transform(predicted)\n",
    "y_test_original = scaler.inverse_transform(y_test)\n",
    "\n",
    "# Avaliar o modelo\n",
    "mae = mean_absolute_error(y_test_original, predicted)\n",
    "mse = mean_squared_error(y_test_original, predicted)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test_original, predicted)\n",
    "me = np.mean(y_test_original - predicted)\n",
    "mav = np.mean(np.abs(y_test_original))\n",
    "mpv = np.mean(np.abs((y_test_original - predicted) / y_test_original))\n",
    "rme = np.mean((y_test_original - predicted) / y_test_original)\n",
    "rmae = np.mean(np.abs(y_test_original - predicted) / np.abs(y_test_original))\n",
    "\n",
    "print(\"Modelo: LSTM\")\n",
    "print(f'MAE: {mae}')\n",
    "print(f'MSE: {mse}')\n",
    "print(f'RMSE: {rmse}')\n",
    "print(f'R2: {r2}')\n",
    "print(f'ME: {me}')\n",
    "print(f'MAV: {mav}')\n",
    "print(f'MPV: {mpv}')\n",
    "print(f'RME: {rme}')\n",
    "print(f'RMAE: {rmae}')\n",
    "\n",
    "# Modelo: LSTM shuffle\n",
    "# MAE: 0.16014973584370207\n",
    "# MSE: 0.33738311706745655\n",
    "# RMSE: 0.5808468964085601\n",
    "# R2: 0.9108013224919652\n",
    "# ME: 0.060484750160230964\n",
    "# MAV: 11.2438539313933\n",
    "# MPV: 0.01255916838360269\n",
    "# RME: 0.004577696164292376\n",
    "# RMAE: 0.01255916838360269\n",
    "\n",
    "\n",
    "# Recuperar as datas associadas ao conjunto de teste\n",
    "dates_test = d4['Screening_date'].values[-len(y_test):]\n",
    "\n",
    "# Plotando os valores reais vs. previsões ao longo do tempo\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(d4['Screening_date'], d4['nscreens'], color='black', label='Actual values')\n",
    "plt.plot(dates_test, predicted, color='blue', label='Predicted values')\n",
    "plt.title('Actual vs Predicted Values for LSTM model')\n",
    "plt.xlabel('Screenings Date')\n",
    "plt.ylabel('Screenings Count')\n",
    "plt.legend()\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Patyc\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 106ms/step - loss: 0.4061 - val_loss: 0.1279\n",
      "Epoch 2/20\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.2036 - val_loss: 0.0366\n",
      "Epoch 3/20\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0530 - val_loss: 0.0118\n",
      "Epoch 4/20\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0084 - val_loss: 0.0483\n",
      "Epoch 5/20\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0248 - val_loss: 0.0157\n",
      "Epoch 6/20\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 9.8878e-04 - val_loss: 0.0072\n",
      "Epoch 7/20\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0054 - val_loss: 0.0073\n",
      "Epoch 8/20\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0054 - val_loss: 0.0083\n",
      "Epoch 9/20\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 6.3532e-04 - val_loss: 0.0138\n",
      "Epoch 10/20\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 8.9567e-04 - val_loss: 0.0159\n",
      "Epoch 11/20\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0011 - val_loss: 0.0121\n",
      "Epoch 12/20\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 4.7382e-05 - val_loss: 0.0097\n",
      "Epoch 13/20\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 3.2395e-04 - val_loss: 0.0098\n",
      "Epoch 14/20\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.8029e-04 - val_loss: 0.0113\n",
      "Epoch 15/20\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.6707e-05 - val_loss: 0.0124\n",
      "Epoch 16/20\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 9.0894e-05 - val_loss: 0.0118\n",
      "Epoch 17/20\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.3227e-05 - val_loss: 0.0109\n",
      "Epoch 18/20\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.8583e-05 - val_loss: 0.0108\n",
      "Epoch 19/20\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.5423e-05 - val_loss: 0.0113\n",
      "Epoch 20/20\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.4687e-06 - val_loss: 0.0116\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step  \n",
      "Fold 2\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Patyc\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - loss: 0.1656 - val_loss: 0.0013\n",
      "Epoch 2/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0107 - val_loss: 0.0190\n",
      "Epoch 3/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0072 - val_loss: 0.0015\n",
      "Epoch 4/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0073 - val_loss: 0.0047\n",
      "Epoch 5/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0030 - val_loss: 0.0078\n",
      "Epoch 6/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0025 - val_loss: 0.0027\n",
      "Epoch 7/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0023 - val_loss: 0.0037\n",
      "Epoch 8/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0026 - val_loss: 0.0029\n",
      "Epoch 9/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0021 - val_loss: 0.0018\n",
      "Epoch 10/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0020 - val_loss: 0.0018\n",
      "Epoch 11/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0012 - val_loss: 9.9466e-04\n",
      "Epoch 12/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0011 - val_loss: 7.9163e-04\n",
      "Epoch 13/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0012 - val_loss: 5.7338e-04\n",
      "Epoch 14/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0015 - val_loss: 4.7170e-04\n",
      "Epoch 15/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0013 - val_loss: 4.0007e-04\n",
      "Epoch 16/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0010 - val_loss: 3.8562e-04\n",
      "Epoch 17/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0012 - val_loss: 3.8750e-04\n",
      "Epoch 18/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 6.2126e-04 - val_loss: 4.9613e-04\n",
      "Epoch 19/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 6.6303e-04 - val_loss: 4.3671e-04\n",
      "Epoch 20/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 8.6930e-04 - val_loss: 5.2665e-04\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step  \n",
      "Fold 3\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Patyc\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - loss: 0.1490 - val_loss: 0.0204\n",
      "Epoch 2/20\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0128 - val_loss: 0.0163\n",
      "Epoch 3/20\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0065 - val_loss: 0.0151\n",
      "Epoch 4/20\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0039 - val_loss: 0.0131\n",
      "Epoch 5/20\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0023 - val_loss: 0.0090\n",
      "Epoch 6/20\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0015 - val_loss: 0.0066\n",
      "Epoch 7/20\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0014 - val_loss: 0.0051\n",
      "Epoch 8/20\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 8.4272e-04 - val_loss: 0.0041\n",
      "Epoch 9/20\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 7.8101e-04 - val_loss: 0.0038\n",
      "Epoch 10/20\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 6.8137e-04 - val_loss: 0.0036\n",
      "Epoch 11/20\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 7.9038e-04 - val_loss: 0.0039\n",
      "Epoch 12/20\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0013 - val_loss: 0.0038\n",
      "Epoch 13/20\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 7.7266e-04 - val_loss: 0.0040\n",
      "Epoch 14/20\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 7.1548e-04 - val_loss: 0.0037\n",
      "Epoch 15/20\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0011 - val_loss: 0.0040\n",
      "Epoch 16/20\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0012 - val_loss: 0.0041\n",
      "Epoch 17/20\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 6.7721e-04 - val_loss: 0.0038\n",
      "Epoch 18/20\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5.9251e-04 - val_loss: 0.0037\n",
      "Epoch 19/20\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0011 - val_loss: 0.0037\n",
      "Epoch 20/20\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 5.5205e-04 - val_loss: 0.0036\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step  \n",
      "Fold 4\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Patyc\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - loss: 0.1007 - val_loss: 0.0403\n",
      "Epoch 2/20\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0133 - val_loss: 0.0064\n",
      "Epoch 3/20\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0048 - val_loss: 0.0021\n",
      "Epoch 4/20\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0025 - val_loss: 6.3837e-05\n",
      "Epoch 5/20\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0014 - val_loss: 1.5302e-06\n",
      "Epoch 6/20\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0020 - val_loss: 6.1532e-05\n",
      "Epoch 7/20\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0023 - val_loss: 1.1629e-04\n",
      "Epoch 8/20\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0016 - val_loss: 4.6478e-05\n",
      "Epoch 9/20\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0013 - val_loss: 1.0586e-05\n",
      "Epoch 10/20\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0017 - val_loss: 5.5599e-06\n",
      "Epoch 11/20\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0019 - val_loss: 6.4347e-05\n",
      "Epoch 12/20\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0016 - val_loss: 8.8750e-05\n",
      "Epoch 13/20\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 8.2248e-04 - val_loss: 4.0580e-05\n",
      "Epoch 14/20\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0018 - val_loss: 6.2424e-05\n",
      "Epoch 15/20\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0013 - val_loss: 9.2060e-05\n",
      "Epoch 16/20\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 9.8789e-04 - val_loss: 4.8346e-05\n",
      "Epoch 17/20\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0013 - val_loss: 2.5944e-05\n",
      "Epoch 18/20\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0013 - val_loss: 2.2623e-05\n",
      "Epoch 19/20\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0020 - val_loss: 2.8321e-05\n",
      "Epoch 20/20\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0019 - val_loss: 1.8068e-05\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step  \n",
      "Fold 5\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Patyc\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - loss: 0.0798 - val_loss: 0.0285\n",
      "Epoch 2/20\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0077 - val_loss: 0.0245\n",
      "Epoch 3/20\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0016 - val_loss: 0.0321\n",
      "Epoch 4/20\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0016 - val_loss: 0.0266\n",
      "Epoch 5/20\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0012 - val_loss: 0.0248\n",
      "Epoch 6/20\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0015 - val_loss: 0.0251\n",
      "Epoch 7/20\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0020 - val_loss: 0.0251\n",
      "Epoch 8/20\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0016 - val_loss: 0.0242\n",
      "Epoch 9/20\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0011 - val_loss: 0.0245\n",
      "Epoch 10/20\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 9.4974e-04 - val_loss: 0.0239\n",
      "Epoch 11/20\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0015 - val_loss: 0.0234\n",
      "Epoch 12/20\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0011 - val_loss: 0.0246\n",
      "Epoch 13/20\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0011 - val_loss: 0.0233\n",
      "Epoch 14/20\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0011 - val_loss: 0.0230\n",
      "Epoch 15/20\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 9.0170e-04 - val_loss: 0.0238\n",
      "Epoch 16/20\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 6.1362e-04 - val_loss: 0.0229\n",
      "Epoch 17/20\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0012 - val_loss: 0.0232\n",
      "Epoch 18/20\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0013 - val_loss: 0.0225\n",
      "Epoch 19/20\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 8.6448e-04 - val_loss: 0.0223\n",
      "Epoch 20/20\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 9.4525e-04 - val_loss: 0.0229\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step  \n",
      "Total - R2: 0.9245, MAE: 0.1619, RMSE: 0.3708\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "\n",
    "# Normalização dos dados da coluna 'nscreens'\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled_data = scaler.fit_transform(d4['nscreens'].values.reshape(-1, 1))\n",
    "\n",
    "# Função para criar sequências de dados\n",
    "def create_sequences(data, seq_length):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - seq_length):\n",
    "        X.append(data[i:i+seq_length])\n",
    "        y.append(data[i+seq_length])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# Definir o tamanho da sequência (por exemplo, 7 dias)\n",
    "seq_length = 7\n",
    "X, y = create_sequences(scaled_data, seq_length)\n",
    "\n",
    "# Configuração da validação cruzada com preservação da sequência temporal\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "# Variáveis para armazenar as previsões e valores reais de todos os folds de TESTE\n",
    "all_y_test_inv = []\n",
    "all_y_pred_inv = []\n",
    "\n",
    "# Iteração sobre os splits de treinamento e teste\n",
    "for fold, (train_index, test_index) in enumerate(tscv.split(X)):\n",
    "    print(f\"Fold {fold + 1}\")\n",
    "\n",
    "    # Dividindo os dados de treino e teste mantendo a sequência temporal\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    # Construir o modelo LSTM\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units=50, return_sequences=True, input_shape=(X_train.shape[1], 1)))\n",
    "    model.add(LSTM(units=50))\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "    # Treinamento do modelo\n",
    "    history = model.fit(X_train, y_train, epochs=20, batch_size=32, validation_data=(X_test, y_test), verbose=1)\n",
    "\n",
    "    # Fazer previsões no conjunto de teste\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Inverter a normalização para calcular as métricas no mesmo espaço dos dados originais\n",
    "    y_test_inv = scaler.inverse_transform(y_test.reshape(-1, 1))\n",
    "    y_pred_inv = scaler.inverse_transform(y_pred)\n",
    "\n",
    "    # Armazenar apenas as previsões e os valores reais de TESTE\n",
    "    all_y_test_inv.extend(y_test_inv.flatten())\n",
    "    all_y_pred_inv.extend(y_pred_inv.flatten())\n",
    "\n",
    "# Convertendo as listas acumuladas para arrays numpy\n",
    "all_y_test_inv = np.array(all_y_test_inv)\n",
    "all_y_pred_inv = np.array(all_y_pred_inv)\n",
    "\n",
    "# Calcular as métricas globais apenas nos dados de TESTE\n",
    "total_r2 = r2_score(all_y_test_inv, all_y_pred_inv)\n",
    "total_mae = mean_absolute_error(all_y_test_inv, all_y_pred_inv)\n",
    "total_rmse = np.sqrt(mean_squared_error(all_y_test_inv, all_y_pred_inv))\n",
    "\n",
    "print(f\"Total - R2: {total_r2:.4f}, MAE: {total_mae:.4f}, RMSE: {total_rmse:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Patyc\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 105ms/step - loss: 0.3393 - val_loss: 0.1035\n",
      "Epoch 2/20\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.1623 - val_loss: 0.0224\n",
      "Epoch 3/20\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0294 - val_loss: 0.0212\n",
      "Epoch 4/20\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0179 - val_loss: 0.0370\n",
      "Epoch 5/20\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0157 - val_loss: 0.0090\n",
      "Epoch 6/20\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 9.3117e-04 - val_loss: 0.0063\n",
      "Epoch 7/20\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0064 - val_loss: 0.0063\n",
      "Epoch 8/20\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0036 - val_loss: 0.0084\n",
      "Epoch 9/20\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1.5383e-04 - val_loss: 0.0136\n",
      "Epoch 10/20\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0014 - val_loss: 0.0128\n",
      "Epoch 11/20\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 5.4510e-04 - val_loss: 0.0093\n",
      "Epoch 12/20\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.0397e-04 - val_loss: 0.0081\n",
      "Epoch 13/20\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 3.5693e-04 - val_loss: 0.0088\n",
      "Epoch 14/20\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 5.4225e-05 - val_loss: 0.0103\n",
      "Epoch 15/20\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 6.5648e-05 - val_loss: 0.0106\n",
      "Epoch 16/20\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 6.3114e-05 - val_loss: 0.0098\n",
      "Epoch 17/20\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 4.3385e-06 - val_loss: 0.0092\n",
      "Epoch 18/20\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 2.7090e-05 - val_loss: 0.0095\n",
      "Epoch 19/20\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 3.6936e-06 - val_loss: 0.0099\n",
      "Epoch 20/20\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 6.4702e-06 - val_loss: 0.0100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step  \n",
      "Fold 1 - R2: 0.6558, MAE: 0.3044, RMSE: 0.4207\n",
      "Fold 2\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Patyc\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - loss: 0.2103 - val_loss: 9.6515e-04\n",
      "Epoch 2/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0127 - val_loss: 0.0291\n",
      "Epoch 3/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0131 - val_loss: 0.0025\n",
      "Epoch 4/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0081 - val_loss: 0.0035\n",
      "Epoch 5/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0037 - val_loss: 0.0108\n",
      "Epoch 6/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0036 - val_loss: 0.0045\n",
      "Epoch 7/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0026 - val_loss: 0.0034\n",
      "Epoch 8/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0025 - val_loss: 0.0046\n",
      "Epoch 9/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0030 - val_loss: 0.0027\n",
      "Epoch 10/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0020 - val_loss: 0.0023\n",
      "Epoch 11/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 12/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0016 - val_loss: 0.0011\n",
      "Epoch 13/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0010 - val_loss: 7.6327e-04\n",
      "Epoch 14/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0012 - val_loss: 5.7015e-04\n",
      "Epoch 15/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 9.5150e-04 - val_loss: 4.3510e-04\n",
      "Epoch 16/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 7.7392e-04 - val_loss: 3.8647e-04\n",
      "Epoch 17/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 6.2787e-04 - val_loss: 3.9396e-04\n",
      "Epoch 18/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0011 - val_loss: 3.8530e-04\n",
      "Epoch 19/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 9.8588e-04 - val_loss: 4.8231e-04\n",
      "Epoch 20/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0012 - val_loss: 4.2483e-04\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step  \n",
      "Fold 2 - R2: 0.8334, MAE: 0.0300, RMSE: 0.0869\n",
      "Fold 3\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Patyc\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - loss: 0.1273 - val_loss: 0.0366\n",
      "Epoch 2/20\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0150 - val_loss: 0.0111\n",
      "Epoch 3/20\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0069 - val_loss: 0.0160\n",
      "Epoch 4/20\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0034 - val_loss: 0.0086\n",
      "Epoch 5/20\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0023 - val_loss: 0.0078\n",
      "Epoch 6/20\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0019 - val_loss: 0.0049\n",
      "Epoch 7/20\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 9.9718e-04 - val_loss: 0.0040\n",
      "Epoch 8/20\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 6.6325e-04 - val_loss: 0.0036\n",
      "Epoch 9/20\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0011 - val_loss: 0.0037\n",
      "Epoch 10/20\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 9.1132e-04 - val_loss: 0.0036\n",
      "Epoch 11/20\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 8.5088e-04 - val_loss: 0.0036\n",
      "Epoch 12/20\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 9.6724e-04 - val_loss: 0.0035\n",
      "Epoch 13/20\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 5.7125e-04 - val_loss: 0.0035\n",
      "Epoch 14/20\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0012 - val_loss: 0.0037\n",
      "Epoch 15/20\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 9.2394e-04 - val_loss: 0.0037\n",
      "Epoch 16/20\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0010 - val_loss: 0.0036\n",
      "Epoch 17/20\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 9.8964e-04 - val_loss: 0.0038\n",
      "Epoch 18/20\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 9.3390e-04 - val_loss: 0.0037\n",
      "Epoch 19/20\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0010 - val_loss: 0.0038\n",
      "Epoch 20/20\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 9.6734e-04 - val_loss: 0.0038\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step  \n",
      "Fold 3 - R2: 0.8362, MAE: 0.1260, RMSE: 0.2612\n",
      "Fold 4\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Patyc\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - loss: 0.1013 - val_loss: 0.0438\n",
      "Epoch 2/20\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0148 - val_loss: 0.0065\n",
      "Epoch 3/20\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0054 - val_loss: 0.0041\n",
      "Epoch 4/20\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0017 - val_loss: 2.2768e-04\n",
      "Epoch 5/20\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0017 - val_loss: 7.8121e-08\n",
      "Epoch 6/20\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0016 - val_loss: 9.3017e-05\n",
      "Epoch 7/20\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0010 - val_loss: 9.4336e-05\n",
      "Epoch 8/20\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0018 - val_loss: 4.9622e-05\n",
      "Epoch 9/20\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0014 - val_loss: 3.2767e-05\n",
      "Epoch 10/20\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0015 - val_loss: 4.8500e-05\n",
      "Epoch 11/20\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0013 - val_loss: 5.9044e-05\n",
      "Epoch 12/20\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0017 - val_loss: 1.7788e-05\n",
      "Epoch 13/20\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0017 - val_loss: 3.8086e-05\n",
      "Epoch 14/20\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0011 - val_loss: 1.5637e-05\n",
      "Epoch 15/20\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0017 - val_loss: 5.0269e-05\n",
      "Epoch 16/20\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0014 - val_loss: 8.0994e-05\n",
      "Epoch 17/20\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0011 - val_loss: 8.6135e-06\n",
      "Epoch 18/20\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0010 - val_loss: 4.8921e-05\n",
      "Epoch 19/20\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0011 - val_loss: 4.9983e-05\n",
      "Epoch 20/20\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0014 - val_loss: 2.6602e-05\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step  \n",
      "Fold 4 - R2: -149951191111817074325848064.0000, MAE: 0.0218, RMSE: 0.0218\n",
      "Fold 5\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Patyc\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - loss: 0.0614 - val_loss: 0.0444\n",
      "Epoch 2/20\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0054 - val_loss: 0.0242\n",
      "Epoch 3/20\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0011 - val_loss: 0.0262\n",
      "Epoch 4/20\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 8.0775e-04 - val_loss: 0.0233\n",
      "Epoch 5/20\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0013 - val_loss: 0.0235\n",
      "Epoch 6/20\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0010 - val_loss: 0.0236\n",
      "Epoch 7/20\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0016 - val_loss: 0.0235\n",
      "Epoch 8/20\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0012 - val_loss: 0.0232\n",
      "Epoch 9/20\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0012 - val_loss: 0.0232\n",
      "Epoch 10/20\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 8.6054e-04 - val_loss: 0.0231\n",
      "Epoch 11/20\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 6.9564e-04 - val_loss: 0.0232\n",
      "Epoch 12/20\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0012 - val_loss: 0.0231\n",
      "Epoch 13/20\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0015 - val_loss: 0.0226\n",
      "Epoch 14/20\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0012 - val_loss: 0.0225\n",
      "Epoch 15/20\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0015 - val_loss: 0.0225\n",
      "Epoch 16/20\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 8.7702e-04 - val_loss: 0.0239\n",
      "Epoch 17/20\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0018 - val_loss: 0.0220\n",
      "Epoch 18/20\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 9.3970e-04 - val_loss: 0.0220\n",
      "Epoch 19/20\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0013 - val_loss: 0.0220\n",
      "Epoch 20/20\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 9.1722e-04 - val_loss: 0.0219\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step  \n",
      "Fold 5 - R2: 0.8785, MAE: 0.2198, RMSE: 0.6242\n",
      "Average - R2: -29990238222363415724163072.0000 ± 59980476444726831448326144.0000, MAE: 0.1404 ± 0.1093, RMSE: 0.2829 ± 0.2203\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "\n",
    "# Normalização dos dados da coluna 'nscreens'\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled_data = scaler.fit_transform(d4['nscreens'].values.reshape(-1, 1))\n",
    "\n",
    "# Função para criar sequências de dados\n",
    "def create_sequences(data, seq_length):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - seq_length):\n",
    "        X.append(data[i:i+seq_length])\n",
    "        y.append(data[i+seq_length])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# Definir o tamanho da sequência (por exemplo, 7 dias)\n",
    "seq_length = 7\n",
    "X, y = create_sequences(scaled_data, seq_length)\n",
    "\n",
    "# Configuração da validação cruzada com preservação da sequência temporal\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "# Listas para armazenar as métricas de cada fold\n",
    "r2_scores = []\n",
    "mae_scores = []\n",
    "rmse_scores = []\n",
    "\n",
    "# Iteração sobre os splits de treinamento e teste\n",
    "for fold, (train_index, test_index) in enumerate(tscv.split(X)):\n",
    "    print(f\"Fold {fold + 1}\")\n",
    "\n",
    "    # Dividindo os dados de treino e teste mantendo a sequência temporal\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    # Construir o modelo LSTM\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units=50, return_sequences=True, input_shape=(X_train.shape[1], 1)))\n",
    "    model.add(LSTM(units=50))\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "    # Treinamento do modelo\n",
    "    history = model.fit(X_train, y_train, epochs=20, batch_size=32, validation_data=(X_test, y_test), verbose=1)\n",
    "\n",
    "    # Fazer previsões no conjunto de teste\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Inverter a normalização para calcular as métricas no mesmo espaço dos dados originais\n",
    "    y_test_inv = scaler.inverse_transform(y_test.reshape(-1, 1))\n",
    "    y_pred_inv = scaler.inverse_transform(y_pred)\n",
    "\n",
    "    # Calcular as métricas para este fold\n",
    "    fold_r2 = r2_score(y_test_inv, y_pred_inv)\n",
    "    fold_mae = mean_absolute_error(y_test_inv, y_pred_inv)\n",
    "    fold_rmse = np.sqrt(mean_squared_error(y_test_inv, y_pred_inv))\n",
    "\n",
    "    # Armazenar as métricas deste fold\n",
    "    r2_scores.append(fold_r2)\n",
    "    mae_scores.append(fold_mae)\n",
    "    rmse_scores.append(fold_rmse)\n",
    "\n",
    "    print(f\"Fold {fold + 1} - R2: {fold_r2:.4f}, MAE: {fold_mae:.4f}, RMSE: {fold_rmse:.4f}\")\n",
    "\n",
    "# Calcular as métricas médias e desvio padrão\n",
    "mean_r2 = np.mean(r2_scores)\n",
    "mean_mae = np.mean(mae_scores)\n",
    "mean_rmse = np.mean(rmse_scores)\n",
    "\n",
    "std_r2 = np.std(r2_scores)\n",
    "std_mae = np.std(mae_scores)\n",
    "std_rmse = np.std(rmse_scores)\n",
    "\n",
    "print(f\"Average - R2: {mean_r2:.4f} ± {std_r2:.4f}, MAE: {mean_mae:.4f} ± {std_mae:.4f}, RMSE: {mean_rmse:.4f} ± {std_rmse:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
