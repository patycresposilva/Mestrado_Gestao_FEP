{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **KNN REGRESSION - CAR RADIOS**"
      ],
      "metadata": {
        "id": "Puo0nANwJhug"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import FunctionTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
        "# from sklearn.linear_model import LinearRegression\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "\n",
        "import datetime\n",
        "\n",
        "df = pd.read_excel('/content/data_carradios.xlsx')\n",
        "\n",
        "def get_ages(col):\n",
        "  result = (datetime.datetime.now()-col).astype('<m8[Y]')\n",
        "  result = pd.DataFrame(result)\n",
        "  return result\n",
        "\n",
        "ager = Pipeline([\n",
        "    ('ages', FunctionTransformer(get_ages, feature_names_out='one-to-one')),\n",
        "    ('scale', StandardScaler())\n",
        "])\n",
        "\n",
        "def get_weekdays(col):\n",
        "  result = col.iloc[:,0].dt.weekday\n",
        "  result = pd.DataFrame(result)\n",
        "  return result\n",
        "\n",
        "weeker = Pipeline([\n",
        "    ('weekd', FunctionTransformer(get_weekdays, feature_names_out='one-to-one')),\n",
        "    # ('oneh', OneHotEncoder(drop='first'))\n",
        "    ('oneh', OneHotEncoder())\n",
        "])\n",
        "\n",
        "# tirámos o drop first porque em KNN não existe multicolinearidade\n",
        "\n",
        "preprocessor = ColumnTransformer([\n",
        "    ('ages_tr', ager, ['bdate']),\n",
        "    ('weekd_tr', weeker, ['datep']),\n",
        "    # ('team_tr', OneHotEncoder(drop='first'), ['team']),\n",
        "    ('team_tr', OneHotEncoder(), ['team']),\n",
        "    ('scaler', StandardScaler(), ['prized', 'prizeq'])],\n",
        "    remainder='passthrough')\n",
        "\n",
        "X = df.drop('perc_defec', axis=1)\n",
        "y = df['perc_defec']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=45)\n",
        "\n",
        "pipe = Pipeline([\n",
        "    ('pre', preprocessor),\n",
        "    # ('lm', LinearRegression())])\n",
        "    ('knn', KNeighborsRegressor(n_neighbors=3))])\n",
        "\n",
        "pipe.fit(X_train, y_train)\n",
        "\n",
        "y_pred = pipe.predict(X_train)\n",
        "\n",
        "mae = mean_absolute_error(y_train, y_pred)\n",
        "rsme = mean_squared_error(y_train, y_pred, squared=False)\n",
        "r2 = r2_score(y_train, y_pred)\n",
        "\n",
        "print(f'MAE= {mae}')\n",
        "print(f'RSME= {rsme}')\n",
        "print(f'R2= {r2}')\n",
        "y_pred = pipe.predict(X_test)\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "rsme = mean_squared_error(y_test, y_pred, squared=False)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(f'MAE= {mae}')\n",
        "print(f'RSME= {rsme}')\n",
        "print(f'R2= {r2}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vo-w04qgJiHb",
        "outputId": "5b08bf68-8013-45fa-d798-fb3c14ea6515"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MAE= 3.0324041666666672\n",
            "RSME= 4.198885925324585\n",
            "R2= 0.922469072562689\n",
            "MAE= 4.002416666666667\n",
            "RSME= 5.326234989809094\n",
            "R2= 0.879513683327535\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **GRID SEARCH CV**\n",
        "\n",
        "In the case of KNN, applying GridSearchCV means find the hyperparameter `n_neighbors` that leads to the best predictive performance of the model.\n",
        "\n",
        "In the LassoRegression we try to find the best alpha for the model, and now, we want to fin the best K."
      ],
      "metadata": {
        "id": "IpzgiOl4J2Pf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D3zp-y-7JVLR",
        "outputId": "78481954-75e3-4144-dc1a-e56ecc8c57c8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MAE= 3.0302549999999995\n",
            "RSME= 4.062708178050695\n",
            "R2= 0.927416470307902\n",
            "MAE= 3.88707\n",
            "RSME= 5.2391171603620394\n",
            "R2= 0.8834228852593191\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import FunctionTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
        "# from sklearn.linear_model import LinearRegression\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.model_selection import GridSearchCV # new\n",
        "\n",
        "import datetime\n",
        "\n",
        "df = pd.read_excel('/content/data_carradios.xlsx')\n",
        "\n",
        "def get_ages(col):\n",
        "  result = (datetime.datetime.now()-col).astype('<m8[Y]')\n",
        "  result = pd.DataFrame(result)\n",
        "  return result\n",
        "\n",
        "ager = Pipeline([\n",
        "    ('ages', FunctionTransformer(get_ages, feature_names_out='one-to-one')),\n",
        "    ('scale', StandardScaler())\n",
        "])\n",
        "\n",
        "def get_weekdays(col):\n",
        "  result = col.iloc[:,0].dt.weekday\n",
        "  result = pd.DataFrame(result)\n",
        "  return result\n",
        "\n",
        "weeker = Pipeline([\n",
        "    ('weekd', FunctionTransformer(get_weekdays, feature_names_out='one-to-one')),\n",
        "    # ('oneh', OneHotEncoder(drop='first'))\n",
        "    ('oneh', OneHotEncoder())\n",
        "\n",
        "])\n",
        "\n",
        "preprocessor = ColumnTransformer([\n",
        "    ('ages_tr', ager, ['bdate']),\n",
        "    ('weekd_tr', weeker, ['datep']),\n",
        "    # ('team_tr', OneHotEncoder(drop='first'), ['team']),\n",
        "    ('team_tr', OneHotEncoder(), ['team']),\n",
        "    ('scaler', StandardScaler(), ['prized', 'prizeq'])],\n",
        "    remainder='passthrough')\n",
        "\n",
        "X = df.drop('perc_defec', axis=1)\n",
        "y = df['perc_defec']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=45)\n",
        "\n",
        "hyperparameters ={ #new\n",
        "    'n_neighbors': [2, 3, 5, 6, 8, 10] \n",
        "}\n",
        "\n",
        "pipe = Pipeline([\n",
        "    ('pre', preprocessor),\n",
        "    # ('lm', LinearRegression())])\n",
        "    # ('knn', KNeighborsRegressor(n_neighbors=3))])\n",
        "    ('grid', GridSearchCV(KNeighborsRegressor(), hyperparameters, cv=5))]) # new\n",
        "\n",
        "pipe.fit(X_train, y_train)\n",
        "\n",
        "y_pred = pipe.predict(X_train)\n",
        "\n",
        "mae = mean_absolute_error(y_train, y_pred)\n",
        "rsme = mean_squared_error(y_train, y_pred, squared=False)\n",
        "r2 = r2_score(y_train, y_pred)\n",
        "\n",
        "print(f'MAE= {mae}')\n",
        "print(f'RSME= {rsme}')\n",
        "print(f'R2= {r2}')\n",
        "\n",
        "y_pred = pipe.predict(X_test)\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "rsme = mean_squared_error(y_test, y_pred, squared=False)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(f'MAE= {mae}')\n",
        "print(f'RSME= {rsme}')\n",
        "print(f'R2= {r2}')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To know what is the K that leads to the better predictive performance of the model:"
      ],
      "metadata": {
        "id": "jY92gfpWKoNf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pipe.named_steps['grid'].best_params_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5E9beeaFKuB5",
        "outputId": "b48cfb79-c11e-4d46-93bf-029a05ff108a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'n_neighbors': 5}"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "So, in order to get the best predictive performance of the model we should use a K=5 instead of using a K=3."
      ],
      "metadata": {
        "id": "S3gL1rTHKwim"
      }
    }
  ]
}