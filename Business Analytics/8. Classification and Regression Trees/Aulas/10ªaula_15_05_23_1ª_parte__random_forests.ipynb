{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Random forests - Bank marketing campaign**\n",
        "\n",
        "**Classification problem**"
      ],
      "metadata": {
        "id": "up8xetFoVb5D"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "626b9832-fc21-47f7-d3dd-7e1210587b8c",
        "id": "VdCLRBSkztyV"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy= 1.0\n",
            "[[ 3700     0]\n",
            " [    0 29250]]\n",
            "Recall= 1.0\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "df = pd.read_csv('/content/bank_mark_campaign.csv', sep=';')\n",
        "\n",
        "df = df.replace('unknown', np.nan) \n",
        "\n",
        "col_nan = df.columns[df.isna().any(axis=0)].to_list()\n",
        "col_num = df.describe().columns.to_list()\n",
        "df.columns.difference(col_nan + col_num)\n",
        "col_cat = df.columns.difference(col_nan + col_num + ['y']).to_list()\n",
        "\n",
        "na_treat = Pipeline([\n",
        "    ('imp', SimpleImputer(strategy='most_frequent')),\n",
        "    ('oneh', OneHotEncoder(drop='first'))])\n",
        "\n",
        "preprocessor = ColumnTransformer([\n",
        "    ('na_tr', na_treat, col_nan),\n",
        "    ('cat_tr', OneHotEncoder(drop='first'), col_cat),\n",
        "    ('scale_tr', StandardScaler(), col_num)], \n",
        "    remainder='passthrough')\n",
        "\n",
        "# hyper = {\n",
        "#     'ccp_alpha': [0.001, 0.01, 0.1, 0.2, 0.5]\n",
        "# }\n",
        "\n",
        "# pipe = Pipeline([\n",
        "#     ('pre', preprocessor),\n",
        "#     ('grid', GridSearchCV(DecisionTreeClassifier(class_weight=\"balanced\"), hyper, cv=5, scoring='roc_auc'))])\n",
        "\n",
        "pipe = Pipeline([\n",
        "    ('pre', preprocessor),\n",
        "    ('rf', RandomForestClassifier())])\n",
        "\n",
        "X = df.drop('y', axis=1)\n",
        "y = df['y']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=45)\n",
        "\n",
        "pipe.fit(X_train, y_train)\n",
        "\n",
        "y_pred = pipe.predict(X_train)\n",
        "\n",
        "acur = accuracy_score(y_train, y_pred)\n",
        "print(f'Accuracy= {acur}')\n",
        "cm = confusion_matrix(y_train, y_pred, labels=['yes', 'no'])\n",
        "print(cm)\n",
        "recall = recall_score(y_train, y_pred, pos_label='yes')\n",
        "print(f'Recall= {recall}')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred2 = pipe.predict(X_test)\n",
        "\n",
        "acur = accuracy_score(y_test, y_pred2)\n",
        "print(f'Accuracy= {acur}')\n",
        "cm = confusion_matrix(y_test, y_pred2, labels=['yes', 'no'])\n",
        "print(cm)\n",
        "recall = recall_score(y_test, y_pred2, pos_label='yes')\n",
        "print(f'Recall= {recall}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "61M_yOe2wMGt",
        "outputId": "321004a8-ac08-49c6-84e4-2641d98d6ce2"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy= 0.9100509832483612\n",
            "[[ 429  511]\n",
            " [ 230 7068]]\n",
            "Recall= 0.4563829787234043\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The model is overfitting because the results for the predictive performance are very different, the model is fitting perfectly for the training set, including the noise. And does not fit good with unseen or new data as we can see in the results for the predictive performance with the test set.\n",
        "\n",
        "In fact, the model ir very bad. To be good, ideally, the recall should be closer to 1 and is very bad."
      ],
      "metadata": {
        "id": "QHAVkILUwfPl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "WHAT CAN BE HAPPENING?\n",
        "\n",
        "Maybe the dataset is imbalanced. Let's see.\n"
      ],
      "metadata": {
        "id": "gEPG9E0nxQ9U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y.value_counts(normalize=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lU-o2tWXxV2c",
        "outputId": "3ba73144-6121-4412-8b47-fa607129b9cf"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "no     0.887346\n",
              "yes    0.112654\n",
              "Name: y, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes, it is. One way to solve is to force python to penalize the majority class."
      ],
      "metadata": {
        "id": "D-jEi4G6xu2j"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3dbeaaef-54d0-4abd-f14c-1cd9307b9a31",
        "id": "qwGI3Li2xtl9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy= 0.9999696509863429\n",
            "[[ 3699     1]\n",
            " [    0 29250]]\n",
            "Recall= 0.9997297297297297\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "df = pd.read_csv('/content/bank_mark_campaign.csv', sep=';')\n",
        "\n",
        "df = df.replace('unknown', np.nan) \n",
        "\n",
        "col_nan = df.columns[df.isna().any(axis=0)].to_list()\n",
        "col_num = df.describe().columns.to_list()\n",
        "df.columns.difference(col_nan + col_num)\n",
        "col_cat = df.columns.difference(col_nan + col_num + ['y']).to_list()\n",
        "\n",
        "na_treat = Pipeline([\n",
        "    ('imp', SimpleImputer(strategy='most_frequent')),\n",
        "    ('oneh', OneHotEncoder(drop='first'))])\n",
        "\n",
        "preprocessor = ColumnTransformer([\n",
        "    ('na_tr', na_treat, col_nan),\n",
        "    ('cat_tr', OneHotEncoder(drop='first'), col_cat),\n",
        "    ('scale_tr', StandardScaler(), col_num)], \n",
        "    remainder='passthrough')\n",
        "\n",
        "# hyper = {\n",
        "#     'ccp_alpha': [0.001, 0.01, 0.1, 0.2, 0.5]\n",
        "# }\n",
        "\n",
        "# pipe = Pipeline([\n",
        "#     ('pre', preprocessor),\n",
        "#     ('grid', GridSearchCV(DecisionTreeClassifier(class_weight=\"balanced\"), hyper, cv=5, scoring='roc_auc'))])\n",
        "\n",
        "pipe = Pipeline([\n",
        "    ('pre', preprocessor),\n",
        "    ('rf', RandomForestClassifier(class_weight='balanced'))])\n",
        "\n",
        "X = df.drop('y', axis=1)\n",
        "y = df['y']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=45)\n",
        "\n",
        "pipe.fit(X_train, y_train)\n",
        "\n",
        "y_pred = pipe.predict(X_train)\n",
        "\n",
        "acur = accuracy_score(y_train, y_pred)\n",
        "print(f'Accuracy= {acur}')\n",
        "cm = confusion_matrix(y_train, y_pred, labels=['yes', 'no'])\n",
        "print(cm)\n",
        "recall = recall_score(y_train, y_pred, pos_label='yes')\n",
        "print(f'Recall= {recall}')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred2 = pipe.predict(X_test)\n",
        "\n",
        "acur = accuracy_score(y_test, y_pred2)\n",
        "print(f'Accuracy= {acur}')\n",
        "cm = confusion_matrix(y_test, y_pred2, labels=['yes', 'no'])\n",
        "print(cm)\n",
        "recall = recall_score(y_test, y_pred2, pos_label='yes')\n",
        "print(f'Recall= {recall}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7oD7ahsqx9qY",
        "outputId": "3705164a-ecbe-45c6-b90b-29102458260f"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy= 0.9095654285020636\n",
            "[[ 396  544]\n",
            " [ 201 7097]]\n",
            "Recall= 0.42127659574468085\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Doing the grid search:"
      ],
      "metadata": {
        "id": "d3q4QtuyyLuE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e7e36b7e-fa42-4d0d-87a2-9b47c997566e",
        "id": "nxxNxVUGyJZc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy= 0.8298330804248862\n",
            "[[ 3526   174]\n",
            " [ 5433 23817]]\n",
            "Recall= 0.952972972972973\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "df = pd.read_csv('/content/bank_mark_campaign.csv', sep=';')\n",
        "\n",
        "df = df.replace('unknown', np.nan) \n",
        "\n",
        "col_nan = df.columns[df.isna().any(axis=0)].to_list()\n",
        "col_num = df.describe().columns.to_list()\n",
        "df.columns.difference(col_nan + col_num)\n",
        "col_cat = df.columns.difference(col_nan + col_num + ['y']).to_list()\n",
        "\n",
        "na_treat = Pipeline([\n",
        "    ('imp', SimpleImputer(strategy='most_frequent')),\n",
        "    ('oneh', OneHotEncoder(drop='first'))])\n",
        "\n",
        "preprocessor = ColumnTransformer([\n",
        "    ('na_tr', na_treat, col_nan),\n",
        "    ('cat_tr', OneHotEncoder(drop='first'), col_cat),\n",
        "    ('scale_tr', StandardScaler(), col_num)], \n",
        "    remainder='passthrough')\n",
        "\n",
        "hyper = {\n",
        "    'ccp_alpha': [0.001, 0.01, 0.1, 0.2, 0.5]\n",
        "}\n",
        "\n",
        "# pipe = Pipeline([\n",
        "#     ('pre', preprocessor),\n",
        "#     ('rf', RandomForestClassifier(class_weight='balanced'))])\n",
        "\n",
        "pipe = Pipeline([\n",
        "    ('pre', preprocessor),\n",
        "    ('grid', GridSearchCV(RandomForestClassifier(class_weight=\"balanced\"), hyper, cv=5))])\n",
        "\n",
        "X = df.drop('y', axis=1)\n",
        "y = df['y']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=45)\n",
        "\n",
        "pipe.fit(X_train, y_train)\n",
        "\n",
        "y_pred = pipe.predict(X_train)\n",
        "\n",
        "acur = accuracy_score(y_train, y_pred)\n",
        "print(f'Accuracy= {acur}')\n",
        "cm = confusion_matrix(y_train, y_pred, labels=['yes', 'no'])\n",
        "print(cm)\n",
        "recall = recall_score(y_train, y_pred, pos_label='yes')\n",
        "print(f'Recall= {recall}')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred2 = pipe.predict(X_test)\n",
        "\n",
        "acur = accuracy_score(y_test, y_pred2)\n",
        "print(f'Accuracy= {acur}')\n",
        "cm = confusion_matrix(y_test, y_pred2, labels=['yes', 'no'])\n",
        "print(cm)\n",
        "recall = recall_score(y_test, y_pred2, pos_label='yes')\n",
        "print(f'Recall= {recall}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z630j9hAy1sP",
        "outputId": "b1cc3f1f-faf1-48b0-bb2f-d83cbca8cff1"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy= 0.8241077931536781\n",
            "[[ 884   56]\n",
            " [1393 5905]]\n",
            "Recall= 0.9404255319148936\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Só agora é que o modelo ficou bom!!!"
      ],
      "metadata": {
        "id": "_HFk7fiR4Ede"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Regression trees and Random forests - Data car radios"
      ],
      "metadata": {
        "id": "5-UwK5T2VTId"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import FunctionTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "\n",
        "import datetime\n",
        "\n",
        "df = pd.read_excel('/content/data_carradios.xlsx')\n",
        "\n",
        "def get_ages(col):\n",
        "  result = (datetime.datetime.now()-col).astype('<m8[Y]')\n",
        "  result = pd.DataFrame(result)\n",
        "  return result\n",
        "\n",
        "ager = Pipeline([\n",
        "    ('ages', FunctionTransformer(get_ages, feature_names_out='one-to-one')),\n",
        "    ('scale', StandardScaler())\n",
        "])\n",
        "\n",
        "def get_weekdays(col):\n",
        "  result = col.iloc[:,0].dt.weekday\n",
        "  result = pd.DataFrame(result)\n",
        "  return result\n",
        "\n",
        "weeker = Pipeline([\n",
        "    ('weekd', FunctionTransformer(get_weekdays, feature_names_out='one-to-one')),\n",
        "    ('oneh', OneHotEncoder(drop='first'))\n",
        "])\n",
        "\n",
        "preprocessor = ColumnTransformer([\n",
        "    ('ages_tr', ager, ['bdate']),\n",
        "    ('weekd_tr', weeker, ['datep']),\n",
        "    ('team_tr', OneHotEncoder(drop='first'), ['team']),\n",
        "    ('scaler', StandardScaler(), ['prized', 'prizeq'])],\n",
        "    remainder='passthrough')\n",
        "\n",
        "X = df.drop('perc_defec', axis=1)\n",
        "y = df['perc_defec']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=45)\n",
        "\n",
        "pipe = Pipeline([\n",
        "    ('pre', preprocessor),\n",
        "    #('lm', LinearRegression()),\n",
        "    ('tree', DecisionTreeRegressor())])\n",
        "\n",
        "pipe.fit(X_train, y_train)\n",
        "\n",
        "y_pred = pipe.predict(X_train)\n",
        "\n",
        "mae = mean_absolute_error(y_train, y_pred)\n",
        "rsme = mean_squared_error(y_train, y_pred, squared=False)\n",
        "r2 = r2_score(y_train, y_pred)\n",
        "\n",
        "print(f'MAE= {mae}')\n",
        "print(f'RSME= {rsme}')\n",
        "print(f'R2= {r2}')\n",
        "y_pred = pipe.predict(X_test)\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "rsme = mean_squared_error(y_test, y_pred, squared=False)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(f'MAE= {mae}')\n",
        "print(f'RSME= {rsme}')\n",
        "print(f'R2= {r2}')"
      ],
      "metadata": {
        "id": "OdmJO58ofCeY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e725de50-9a47-45f5-e58f-e6f556c9e99e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MAE= 2.6502624234792984\n",
            "RSME= 3.676162025277643\n",
            "R2= 0.940571315604777\n",
            "MAE= 3.904061677489177\n",
            "RSME= 5.212007208008061\n",
            "R2= 0.8846262266400601\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "R2 => training set => 0.94\n",
        "\n",
        "R2 => test set => 0.88\n",
        "\n",
        "They are too different so we can suspect overfitting. The model don't behave the same way in the test set (unseen data) as it behaves in the training set.\n",
        "\n",
        "We have to play with the complexity of the tree using parameter `ccp_alpha`.\n",
        "\n",
        "We need to do a grid search, define several values for the hyperparameter in order to find the best value of the hyperparameter."
      ],
      "metadata": {
        "id": "pEbZiDs-j36P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV"
      ],
      "metadata": {
        "id": "087CbFGRVhPz"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import FunctionTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "\n",
        "import datetime\n",
        "\n",
        "df = pd.read_excel('/content/data_carradios.xlsx')\n",
        "\n",
        "def get_ages(col):\n",
        "  result = (datetime.datetime.now()-col).astype('<m8[Y]')\n",
        "  result = pd.DataFrame(result)\n",
        "  return result\n",
        "\n",
        "ager = Pipeline([\n",
        "    ('ages', FunctionTransformer(get_ages, feature_names_out='one-to-one')),\n",
        "    ('scale', StandardScaler())\n",
        "])\n",
        "\n",
        "def get_weekdays(col):\n",
        "  result = col.iloc[:,0].dt.weekday\n",
        "  result = pd.DataFrame(result)\n",
        "  return result\n",
        "\n",
        "weeker = Pipeline([\n",
        "    ('weekd', FunctionTransformer(get_weekdays, feature_names_out='one-to-one')),\n",
        "    ('oneh', OneHotEncoder(drop='first'))\n",
        "])\n",
        "\n",
        "preprocessor = ColumnTransformer([\n",
        "    ('ages_tr', ager, ['bdate']),\n",
        "    ('weekd_tr', weeker, ['datep']),\n",
        "    ('team_tr', OneHotEncoder(drop='first'), ['team']),\n",
        "    ('scaler', StandardScaler(), ['prized', 'prizeq'])],\n",
        "    remainder='passthrough')\n",
        "\n",
        "X = df.drop('perc_defec', axis=1)\n",
        "y = df['perc_defec']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=45)\n",
        "\n",
        "hyper = ({\n",
        "    'ccp_alpha': [0.001, 0.003, 0.1, 0.3, 0.5]\n",
        "})\n",
        "\n",
        "pipe = Pipeline([\n",
        "    ('pre', preprocessor),\n",
        "    #('lm', LinearRegression()),\n",
        "    #('tree', DecisionTreeRegressor()),\n",
        "    ('grid', GridSearchCV(DecisionTreeRegressor(), hyper, cv=5))])\n",
        "\n",
        "pipe.fit(X_train, y_train)\n",
        "\n",
        "y_pred = pipe.predict(X_train)\n",
        "\n",
        "mae = mean_absolute_error(y_train, y_pred)\n",
        "rsme = mean_squared_error(y_train, y_pred, squared=False)\n",
        "r2 = r2_score(y_train, y_pred)\n",
        "\n",
        "print(f'MAE= {mae}')\n",
        "print(f'RSME= {rsme}')\n",
        "print(f'R2= {r2}')\n",
        "y_pred = pipe.predict(X_test)\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "rsme = mean_squared_error(y_test, y_pred, squared=False)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(f'MAE= {mae}')\n",
        "print(f'RSME= {rsme}')\n",
        "print(f'R2= {r2}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d6635354-6ba3-49bf-89c8-fe8e1b3b20ae",
        "id": "hIbZtBK4lF5x"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MAE= 3.2898610178578025\n",
            "RSME= 4.271822451632366\n",
            "R2= 0.9197521852026403\n",
            "MAE= 3.6986164844013847\n",
            "RSME= 4.921032250811609\n",
            "R2= 0.8971487666569046\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The overfitting seems not be present since the results of the predictive performance of the model for both sets are similar."
      ],
      "metadata": {
        "id": "HYnL4K7Blymd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "There is a set of hyperparameters in the professor's note that we can use for the final assignment!!!"
      ],
      "metadata": {
        "id": "GFHjTHtfnATx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **RANDOM FORESTS**\n",
        "\n",
        "* it works in both classification and regression problems;\n",
        "\n",
        "* they are specially good for classification;\n",
        "\n",
        "* it used multiple trees;\n",
        "\n",
        "* it may be heavy computationally.\n",
        "\n",
        "See tablet.\n"
      ],
      "metadata": {
        "id": "u1UXkvNnnpvL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**RANDOM FORESTS - REGRESSION**"
      ],
      "metadata": {
        "id": "Gy3rHbPrr9h3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import FunctionTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
        "from sklearn.linear_model import LinearRegression\n",
        "#from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "import datetime\n",
        "\n",
        "df = pd.read_excel('/content/data_carradios.xlsx')\n",
        "\n",
        "def get_ages(col):\n",
        "  result = (datetime.datetime.now()-col).astype('<m8[Y]')\n",
        "  result = pd.DataFrame(result)\n",
        "  return result\n",
        "\n",
        "ager = Pipeline([\n",
        "    ('ages', FunctionTransformer(get_ages, feature_names_out='one-to-one')),\n",
        "    ('scale', StandardScaler())\n",
        "])\n",
        "\n",
        "def get_weekdays(col):\n",
        "  result = col.iloc[:,0].dt.weekday\n",
        "  result = pd.DataFrame(result)\n",
        "  return result\n",
        "\n",
        "weeker = Pipeline([\n",
        "    ('weekd', FunctionTransformer(get_weekdays, feature_names_out='one-to-one')),\n",
        "    ('oneh', OneHotEncoder(drop='first'))\n",
        "])\n",
        "\n",
        "preprocessor = ColumnTransformer([\n",
        "    ('ages_tr', ager, ['bdate']),\n",
        "    ('weekd_tr', weeker, ['datep']),\n",
        "    ('team_tr', OneHotEncoder(drop='first'), ['team']),\n",
        "    ('scaler', StandardScaler(), ['prized', 'prizeq'])],\n",
        "    remainder='passthrough')\n",
        "\n",
        "X = df.drop('perc_defec', axis=1)\n",
        "y = df['perc_defec']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=45)\n",
        "\n",
        "# hyper = ({\n",
        "#     'ccp_alpha': [0.001, 0.003, 0.1, 0.3, 0.5]\n",
        "# })\n",
        "\n",
        "# pipe = Pipeline([\n",
        "#     ('pre', preprocessor),\n",
        "#     #('lm', LinearRegression()),\n",
        "#     #('tree', DecisionTreeRegressor()),\n",
        "#     ('grid', GridSearchCV(DecisionTreeRegressor(), hyper, cv=5))])\n",
        "\n",
        "pipe = Pipeline([\n",
        "    ('pre', preprocessor),\n",
        "    ('rf', RandomForestRegressor())])\n",
        "\n",
        "pipe.fit(X_train, y_train)\n",
        "\n",
        "y_pred = pipe.predict(X_train)\n",
        "\n",
        "mae = mean_absolute_error(y_train, y_pred)\n",
        "rsme = mean_squared_error(y_train, y_pred, squared=False)\n",
        "r2 = r2_score(y_train, y_pred)\n",
        "\n",
        "print(f'MAE= {mae}')\n",
        "print(f'RSME= {rsme}')\n",
        "print(f'R2= {r2}')\n",
        "y_pred = pipe.predict(X_test)\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "rsme = mean_squared_error(y_test, y_pred, squared=False)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(f'MAE= {mae}')\n",
        "print(f'RSME= {rsme}')\n",
        "print(f'R2= {r2}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "93b4f8a5-3b0a-45ca-b8f4-2be5026ca782",
        "id": "mq1pRiyrsL9X"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MAE= 2.7736142523148026\n",
            "RSME= 3.7237695107788875\n",
            "R2= 0.939022107456038\n",
            "MAE= 3.7842542658143907\n",
            "RSME= 5.0773780396263115\n",
            "R2= 0.8905095900145092\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Again, we can be a little bit suspicious of overfitting because there is some difference between the R2 of both sets."
      ],
      "metadata": {
        "id": "OQTbA8Q7tHV8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import FunctionTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
        "from sklearn.linear_model import LinearRegression\n",
        "#from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "import datetime\n",
        "\n",
        "df = pd.read_excel('/content/data_carradios.xlsx')\n",
        "\n",
        "def get_ages(col):\n",
        "  result = (datetime.datetime.now()-col).astype('<m8[Y]')\n",
        "  result = pd.DataFrame(result)\n",
        "  return result\n",
        "\n",
        "ager = Pipeline([\n",
        "    ('ages', FunctionTransformer(get_ages, feature_names_out='one-to-one')),\n",
        "    ('scale', StandardScaler())\n",
        "])\n",
        "\n",
        "def get_weekdays(col):\n",
        "  result = col.iloc[:,0].dt.weekday\n",
        "  result = pd.DataFrame(result)\n",
        "  return result\n",
        "\n",
        "weeker = Pipeline([\n",
        "    ('weekd', FunctionTransformer(get_weekdays, feature_names_out='one-to-one')),\n",
        "    ('oneh', OneHotEncoder(drop='first'))\n",
        "])\n",
        "\n",
        "preprocessor = ColumnTransformer([\n",
        "    ('ages_tr', ager, ['bdate']),\n",
        "    ('weekd_tr', weeker, ['datep']),\n",
        "    ('team_tr', OneHotEncoder(drop='first'), ['team']),\n",
        "    ('scaler', StandardScaler(), ['prized', 'prizeq'])],\n",
        "    remainder='passthrough')\n",
        "\n",
        "X = df.drop('perc_defec', axis=1)\n",
        "y = df['perc_defec']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=45)\n",
        "\n",
        "hyper = ({\n",
        "    'ccp_alpha': [0.001, 0.003, 0.1, 0.3, 0.5],\n",
        "    'n_estimators': [10, 50, 100, 150]\n",
        "})\n",
        "\n",
        "# pipe = Pipeline([\n",
        "#     ('pre', preprocessor),\n",
        "#     ('rf', RandomForestRegressor())])\n",
        "\n",
        "pipe = Pipeline([\n",
        "    ('pre', preprocessor),\n",
        "    ('grid', GridSearchCV(RandomForestRegressor(), hyper, cv=5))])\n",
        "\n",
        "pipe.fit(X_train, y_train)\n",
        "\n",
        "y_pred = pipe.predict(X_train)\n",
        "\n",
        "mae = mean_absolute_error(y_train, y_pred)\n",
        "rsme = mean_squared_error(y_train, y_pred, squared=False)\n",
        "r2 = r2_score(y_train, y_pred)\n",
        "\n",
        "print(f'MAE= {mae}')\n",
        "print(f'RSME= {rsme}')\n",
        "print(f'R2= {r2}')\n",
        "y_pred = pipe.predict(X_test)\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "rsme = mean_squared_error(y_test, y_pred, squared=False)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(f'MAE= {mae}')\n",
        "print(f'RSME= {rsme}')\n",
        "print(f'R2= {r2}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e39e7536-cc00-4aea-a665-60e9d5bcca27",
        "id": "JmNsf415tykj"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MAE= 3.280953030291423\n",
            "RSME= 4.264505828858355\n",
            "R2= 0.9200268408922576\n",
            "MAE= 3.727294990382348\n",
            "RSME= 4.93468758066848\n",
            "R2= 0.8965771727033631\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "What is the best hyperparameter and the best number of trees?"
      ],
      "metadata": {
        "id": "SGMLgmd9u7pp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pipe.named_steps['grid'].best_params_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HOfOcozdu3lH",
        "outputId": "d598bcb6-87d3-45e8-dca5-6c7cec469013"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'ccp_alpha': 0.5, 'n_estimators': 50}"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    }
  ]
}