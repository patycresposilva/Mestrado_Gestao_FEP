{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Neural networks - Bank marketing campaign"
      ],
      "metadata": {
        "id": "up8xetFoVb5D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "0.64-0.1*2*0.64"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Af4UIVQHxb8H",
        "outputId": "cb1fb305-1721-45a7-e2a8-5cec187a47fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.512"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Too high learning rate may lead to convergence loss."
      ],
      "metadata": {
        "id": "QNI06CUgzrG4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "w = 1\n",
        "eta = 1.1\n",
        "n_iter = 100\n",
        "\n",
        "for i in range(n_iter):\n",
        "  w = w - eta * 2 * w  \n",
        "\n",
        "print(w)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wJ0wLfd7yNQH",
        "outputId": "06243929-8850-4710-c601-334c33c9e338"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "82817974.5220158\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8db04dd6-eb03-44df-fb40-023aced31962",
        "id": "VdCLRBSkztyV"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy= 0.9177541729893779\n",
            "[[ 1856  1844]\n",
            " [  866 28384]]\n",
            "Precision= 0.6818515797207936\n",
            "Recall= 0.5016216216216216\n",
            "Accuracy= 0.9113862588006798\n",
            "[[ 451  489]\n",
            " [ 241 7057]]\n",
            "Precision= 0.6517341040462428\n",
            "Recall= 0.4797872340425532\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "df = pd.read_csv('/content/bank_mark_campaign.csv', sep=';')\n",
        "\n",
        "df = df.replace('unknown', np.nan) \n",
        "\n",
        "col_nan = df.columns[df.isna().any(axis=0)].to_list()\n",
        "col_num = df.describe().columns.to_list()\n",
        "df.columns.difference(col_nan + col_num)\n",
        "col_cat = df.columns.difference(col_nan + col_num + ['y']).to_list()\n",
        "\n",
        "na_treat = Pipeline([\n",
        "    ('imp', SimpleImputer(strategy='most_frequent')),\n",
        "    ('oneh', OneHotEncoder(drop='first'))])\n",
        "\n",
        "preprocessor = ColumnTransformer([\n",
        "    ('na_tr', na_treat, col_nan),\n",
        "    ('cat_tr', OneHotEncoder(drop='first'), col_cat),\n",
        "    ('scale_tr', StandardScaler(), col_num)], \n",
        "    remainder='passthrough')\n",
        "\n",
        "# hyper = {\n",
        "#     'ccp_alpha': [0.001, 0.01, 0.1, 0.2, 0.5]\n",
        "# }\n",
        "\n",
        "# pipe = Pipeline([\n",
        "#     ('pre', preprocessor),\n",
        "#     ('grid', GridSearchCV(DecisionTreeClassifier(class_weight=\"balanced\"), hyper, cv=5, scoring='roc_auc'))])\n",
        "\n",
        "pipe = Pipeline([\n",
        "    ('pre', preprocessor),\n",
        "    ('nn', MLPClassifier(hidden_layer_sizes=(5, 3)))]) # using 2 hidden layers with 5 and 3 neuron, respectively\n",
        "\n",
        "\n",
        "X = df.drop('y', axis=1)\n",
        "y = df['y']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=45)\n",
        "\n",
        "pipe.fit(X_train, y_train)\n",
        "\n",
        "# train\n",
        "y_pred = pipe.predict(X_train)\n",
        "\n",
        "acur = accuracy_score(y_train, y_pred)\n",
        "print(f'Accuracy= {acur}')\n",
        "cm = confusion_matrix(y_train, y_pred, labels=['yes', 'no'])\n",
        "print(cm)\n",
        "precision = precision_score(y_train, y_pred, pos_label='yes')\n",
        "print(f'Precision= {precision}')\n",
        "recall = recall_score(y_train, y_pred, pos_label='yes')\n",
        "print(f'Recall= {recall}')\n",
        "\n",
        "# test\n",
        "y_pred = pipe.predict(X_test)\n",
        "\n",
        "acur = accuracy_score(y_test, y_pred)\n",
        "print(f'Accuracy= {acur}')\n",
        "cm = confusion_matrix(y_test, y_pred, labels=['yes', 'no'])\n",
        "print(cm)\n",
        "precision = precision_score(y_test, y_pred, pos_label='yes')\n",
        "print(f'Precision= {precision}')\n",
        "recall = recall_score(y_test, y_pred, pos_label='yes')\n",
        "print(f'Recall= {recall}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   Since the classes are too imblanced (the yes one is very under-represented), we need to compensate for that.\n",
        "*   The neural networks tend to overfit, and we need to use a sort of Lasso regularization to avoid overfitting.\n",
        "\n"
      ],
      "metadata": {
        "id": "tin6_S1a1qFY"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "g3RfeXKY5SlK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7300e71-ca73-4d59-bfc3-6179dd961032",
        "id": "pt_SkWnj5lq3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy= 0.919453717754173\n",
            "[[ 1993  1707]\n",
            " [  947 28303]]\n",
            "Precision= 0.677891156462585\n",
            "Recall= 0.5386486486486487\n",
            "Accuracy= 0.9136926438455936\n",
            "[[ 480  460]\n",
            " [ 251 7047]]\n",
            "Precision= 0.6566347469220246\n",
            "Recall= 0.5106382978723404\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "\n",
        "df = pd.read_csv('/content/bank_mark_campaign.csv', sep=';')\n",
        "\n",
        "df = df.replace('unknown', np.nan) \n",
        "\n",
        "col_nan = df.columns[df.isna().any(axis=0)].to_list()\n",
        "col_num = df.describe().columns.to_list()\n",
        "df.columns.difference(col_nan + col_num)\n",
        "col_cat = df.columns.difference(col_nan + col_num + ['y']).to_list()\n",
        "\n",
        "na_treat = Pipeline([\n",
        "    ('imp', SimpleImputer(strategy='most_frequent')),\n",
        "    ('oneh', OneHotEncoder(drop='first'))])\n",
        "\n",
        "preprocessor = ColumnTransformer([\n",
        "    ('na_tr', na_treat, col_nan),\n",
        "    ('cat_tr', OneHotEncoder(drop='first'), col_cat),\n",
        "    ('scale_tr', StandardScaler(), col_num)], \n",
        "    remainder='passthrough')\n",
        "\n",
        "hyper = {\n",
        "    'alpha': [0.0001, 0.01, 0.2]\n",
        "}\n",
        "\n",
        "pipe = Pipeline([\n",
        "    ('pre', preprocessor),\n",
        "    ('grid', GridSearchCV(MLPClassifier(hidden_layer_sizes=(5, 3)), hyper, cv=5, scoring='roc_auc'))])\n",
        "\n",
        "# pipe = Pipeline([\n",
        "#     ('pre', preprocessor),\n",
        "#     ('nn', MLPClassifier(hidden_layer_sizes=(5, 3)))]) # using 2 hidden layers with 5 and 3 neuron, respectively\n",
        "\n",
        "\n",
        "X = df.drop('y', axis=1)\n",
        "y = df['y']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=45)\n",
        "\n",
        "pipe.fit(X_train, y_train)\n",
        "\n",
        "# train\n",
        "y_pred = pipe.predict(X_train)\n",
        "\n",
        "acur = accuracy_score(y_train, y_pred)\n",
        "print(f'Accuracy= {acur}')\n",
        "cm = confusion_matrix(y_train, y_pred, labels=['yes', 'no'])\n",
        "print(cm)\n",
        "precision = precision_score(y_train, y_pred, pos_label='yes')\n",
        "print(f'Precision= {precision}')\n",
        "recall = recall_score(y_train, y_pred, pos_label='yes')\n",
        "print(f'Recall= {recall}')\n",
        "\n",
        "# test\n",
        "y_pred = pipe.predict(X_test)\n",
        "\n",
        "acur = accuracy_score(y_test, y_pred)\n",
        "print(f'Accuracy= {acur}')\n",
        "cm = confusion_matrix(y_test, y_pred, labels=['yes', 'no'])\n",
        "print(cm)\n",
        "precision = precision_score(y_test, y_pred, pos_label='yes')\n",
        "print(f'Precision= {precision}')\n",
        "recall = recall_score(y_test, y_pred, pos_label='yes')\n",
        "print(f'Recall= {recall}')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KGIFL1Q65ShS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0bfae40a-c600-40fb-a76a-041887046258",
        "id": "krt0thtE8JjZ"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy= 0.8612443095599392\n",
            "[[ 3440   260]\n",
            " [ 4312 24938]]\n",
            "Precision= 0.4437564499484004\n",
            "Recall= 0.9297297297297298\n",
            "Accuracy= 0.8550619082301529\n",
            "[[ 852   88]\n",
            " [1106 6192]]\n",
            "Precision= 0.4351378958120531\n",
            "Recall= 0.9063829787234042\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "\n",
        "\n",
        "df = pd.read_csv('/content/bank_mark_campaign.csv', sep=';')\n",
        "\n",
        "df = df.replace('unknown', np.nan) \n",
        "\n",
        "col_nan = df.columns[df.isna().any(axis=0)].to_list()\n",
        "col_num = df.describe().columns.to_list()\n",
        "df.columns.difference(col_nan + col_num)\n",
        "col_cat = df.columns.difference(col_nan + col_num + ['y']).to_list()\n",
        "\n",
        "na_treat = Pipeline([\n",
        "    ('imp', SimpleImputer(strategy='most_frequent')),\n",
        "    ('oneh', OneHotEncoder(drop='first'))])\n",
        "\n",
        "preprocessor = ColumnTransformer([\n",
        "    ('na_tr', na_treat, col_nan),\n",
        "    ('cat_tr', OneHotEncoder(drop='first'), col_cat),\n",
        "    ('scale_tr', StandardScaler(), col_num)], \n",
        "    remainder='passthrough')\n",
        "\n",
        "hyper = {\n",
        "    'alpha': [0.0001, 0.01, 0.2]\n",
        "}\n",
        "\n",
        "pipe = Pipeline([\n",
        "    # ('pre', preprocessor),\n",
        "    ('grid', GridSearchCV(MLPClassifier(hidden_layer_sizes=(5, 3)), hyper, cv=5, scoring='roc_auc'))])\n",
        "\n",
        "X = df.drop('y', axis=1)\n",
        "y = df['y']\n",
        "\n",
        "X = preprocessor.fit_transform(X) # this transforms the columns outside the pipeline\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=45)\n",
        "\n",
        "ros = RandomOverSampler(random_state=45) # this creates the sampler\n",
        "\n",
        "X_train_res, y_train_res = ros.fit_resample(X_train, y_train) # this does the oversmapling on the training set\n",
        "\n",
        "pipe.fit(X_train_res, y_train_res) # this applies the model to the resampled training set\n",
        "\n",
        "# train\n",
        "y_pred = pipe.predict(X_train)\n",
        "\n",
        "acur = accuracy_score(y_train, y_pred)\n",
        "print(f'Accuracy= {acur}')\n",
        "cm = confusion_matrix(y_train, y_pred, labels=['yes', 'no'])\n",
        "print(cm)\n",
        "precision = precision_score(y_train, y_pred, pos_label='yes')\n",
        "print(f'Precision= {precision}')\n",
        "recall = recall_score(y_train, y_pred, pos_label='yes')\n",
        "print(f'Recall= {recall}')\n",
        "\n",
        "# test\n",
        "y_pred = pipe.predict(X_test)\n",
        "\n",
        "acur = accuracy_score(y_test, y_pred)\n",
        "print(f'Accuracy= {acur}')\n",
        "cm = confusion_matrix(y_test, y_pred, labels=['yes', 'no'])\n",
        "print(cm)\n",
        "precision = precision_score(y_test, y_pred, pos_label='yes')\n",
        "print(f'Precision= {precision}')\n",
        "recall = recall_score(y_test, y_pred, pos_label='yes')\n",
        "print(f'Recall= {recall}')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "852 / (852+1106)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O1qeHoOf5Sdi",
        "outputId": "4dd2172d-34db-4905-c864-7f5d928335a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4351378958120531"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rZGHNrzu5SaK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XMw7ELb45SWp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4mHB0AH25Rq6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Neural networks - Data car radios"
      ],
      "metadata": {
        "id": "5-UwK5T2VTId"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import FunctionTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "\n",
        "import datetime\n",
        "\n",
        "df = pd.read_excel('/content/data_carradios.xlsx')\n",
        "\n",
        "def get_ages(col):\n",
        "  result = (datetime.datetime.now()-col).astype('<m8[Y]')\n",
        "  result = pd.DataFrame(result)\n",
        "  return result\n",
        "\n",
        "ager = Pipeline([\n",
        "    ('ages', FunctionTransformer(get_ages, feature_names_out='one-to-one')),\n",
        "    ('scale', StandardScaler())\n",
        "])\n",
        "\n",
        "def get_weekdays(col):\n",
        "  result = col.iloc[:,0].dt.weekday\n",
        "  result = pd.DataFrame(result)\n",
        "  return result\n",
        "\n",
        "weeker = Pipeline([\n",
        "    ('weekd', FunctionTransformer(get_weekdays, feature_names_out='one-to-one')),\n",
        "    ('oneh', OneHotEncoder(drop='first'))\n",
        "])\n",
        "\n",
        "preprocessor = ColumnTransformer([\n",
        "    ('ages_tr', ager, ['bdate']),\n",
        "    ('weekd_tr', weeker, ['datep']),\n",
        "    ('team_tr', OneHotEncoder(drop='first'), ['team']),\n",
        "    ('scaler', StandardScaler(), ['prized', 'prizeq'])],\n",
        "    remainder='passthrough')\n",
        "\n",
        "X = df.drop('perc_defec', axis=1)\n",
        "y = df['perc_defec']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=45)^\n",
        "\n",
        "hyper = {\n",
        "    'alpha': [],\n",
        "    'hidden_layer_sizes': [(5, 3), ]\n",
        "}\n",
        "\n",
        "pipe = Pipeline([\n",
        "    ('pre', preprocessor),\n",
        "    ('nn', MLPRegressor(max_iter=10000))])\n",
        "\n",
        "pipe.fit(X_train, y_train)\n",
        "\n",
        "# train\n",
        "y_pred = pipe.predict(X_train)\n",
        "\n",
        "mae = mean_absolute_error(y_train, y_pred)\n",
        "rsme = mean_squared_error(y_train, y_pred, squared=False)\n",
        "r2 = r2_score(y_train, y_pred)\n",
        "\n",
        "print(f'MAE= {mae}')\n",
        "print(f'RSME= {rsme}')\n",
        "print(f'R2= {r2}')\n",
        "\n",
        "# test\n",
        "y_pred = pipe.predict(X_test)\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "rsme = mean_squared_error(y_test, y_pred, squared=False)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(f'MAE= {mae}')\n",
        "print(f'RSME= {rsme}')\n",
        "print(f'R2= {r2}')"
      ],
      "metadata": {
        "id": "OdmJO58ofCeY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "28b805af-0fec-4581-c3e3-61953f0cc58e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MAE= 2.9050785626515365\n",
            "RSME= 3.858558520768176\n",
            "R2= 0.9345277886097233\n",
            "MAE= 3.7638325037406144\n",
            "RSME= 5.078833638588232\n",
            "R2= 0.8904468028945378\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "087CbFGRVhPz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}